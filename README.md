# MachineLearning
# author : sunjingpeng6@126.com 
---------------------------------------------------------
HMM.py
隐马尔科夫模型，数学推导见李航《统计学习方法》 第10章
代码实现HMM的3个基本问题步骤
 1. 概率计算问题:前向-后向算法——动态规划
 给定模型λ=(pi, A , B) , 和观测序列 O ,计算模型λ下观测序列O出现的概率P(O| λ)
 2. 学习问题:Baum-Welch算法(状态未知)——EM
 已知观测序列 O  ,估计模型λ = (pi, A , B)的参数,使得在该模型下观测序列P(O|λ)最大
 3. 预测问题:Viterbi算法——动态规划
 解码问题:已知模型λ = (pi, A , B)和观测序列 O
 求给定观测序列条件概率P(I|O, λ )最大的状态序列I
 --------------------------------------------------------
perceptron.py

感知机学习算法的原始形式

具体推导过程见李航《统计学习方法》第2章感知机  2.3.1 感知机学习算法的原始形式

tips:
  1. 感知机(perceptron)是二类分类的线性分类模型,其输入为实例的特征向量,输出
  为实例的类别,取+1和–1二值。
  2. 当训练数据集是线性可分的，感知机算法的原始形式是收敛的。
  --------------------------------------------------------
perceptron_duality.py

感知机学习算法的对偶形式

具体推导过程见李航《统计学习方法》第2章感知机  2.3.3 感知机学习算法的对偶形式
对偶形式中训练实例仅以内积的形式出现。为了方便,可以预先将训练集中实例间的
内积计算出来并以矩阵的形式存储,这个矩阵就是Gram矩阵。

------------------------------------------------------------
kNN.py 

k近邻算法

分类时,对新的实例,根据其k个最近邻的训练实例的类别,
通过多数表决等方式进行预测。
具体推导过程见李航《统计学习方法》第3章 k近邻法 3.2 k近邻模型

-------------------------------------------------------------
kd_tree.py

kd tree 最近邻搜索

具体推导过程见李航《统计学习方法》第3章 k近邻法 3.3 k近邻法的实现:kd树
kd树是二叉树,表示对k维空间的一个划分,其每个结
点对应于k维空间划分中的一个超矩形区域。利用kd树可以省去对大部分数据点的搜索,
从而减少搜索的计算量。

--------------------------------------------------------------
naive_bayes.py

朴素贝叶斯方法分类

参见李航 统计学习方法 第4章 朴素贝叶斯法

朴素贝叶斯(naïve Bayes)法是基于贝叶斯定理与特征条件独立假设的分类方法。
对于给定的训练数据集,首先基于特征条件独立假设学习输入/输出的联合概率分布;
然后基于此模型,对给定的输入x,利用贝叶斯定理求出后验概率最大的输出y。

----------------------------------------------------------
GaussionNB.py

高斯朴素贝叶斯分类 

高斯贝叶斯用来处理连续数据，假设在已经知道数据类别的条件下，数据每个特征独立服从某一高斯分布

--------------------------------------------------------------------------
decision_tree.py

决策树分类与回归

参见李航 统计学习方法 第5章 决策树

------------------------------------------------------------------------------

logistic_regression.py

逻辑回归

参见 李航 第6章 逻辑斯谛回归与最大熵模型 6.1 逻辑斯谛回归模型

这里采用梯度下降求取似然函数的最大值

---------------------------------------------------------------------------

adaboost.py

提升方法

参见 李航 第8章 提升方法 8.1 提升方法AdaBoost算法

---------------------------------------------------------------------------

gradient_boosting.py

梯度提升方法

参见 李航 第8章 提升方法 8.4.3 梯度提升

回归树的损失函数为 平方损失
分类树的损失函数为 交叉熵

------------------------------------------------------------------------------

random_forest.py

随机森林 分类

随机森林是一个包含多个决策树的分类器， 并且其输出的类别是由个别树输出的类别的众数而定。

-------------------------------------------------------------------------------

k_means.py 

典型的基于距离的聚类算法，采用距离作为相似性的评价指标，即认为两个对象的距离越近，其相似度就越大。

该算法认为簇是由距离靠近的对象组成的，因此把得到紧凑且独立的簇作为最终目标。

k个初始类聚类中心点的选取对聚类结果具有较大的影响。

---------------------------------------------------------------------

gaussians_mixture_model.py

多维高斯混合模型 聚类 EM算法

参见 李航 第9章 EM算法及其推广 9.3 EM算法在高斯混合模型学习中的应用

------------------------------------------------------------------------------

stack.py

集成学习方法 stacking

将训练好的所有基模型对训练基进行预测，第j个基模型对第i个训练样本的预测值将作为新的训练集中第i个样本的第j个特征值，最后基于新的训练集进行训练。

同理，预测的过程也要先经过所有基模型的预测形成新的测试集，最后再对测试集进行预测。

