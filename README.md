# MachineLearning
# author : sunjingpeng6@126.com 
---------------------------------------------------------
HMM.py
隐马尔科夫模型，数学推导见李航《统计学习方法》 第10章
代码实现HMM的3个基本问题步骤
 1. 概率计算问题:前向-后向算法——动态规划
 给定模型λ=(pi, A , B) , 和观测序列 O ,计算模型λ下观测序列O出现的概率P(O| λ)
 2. 学习问题:Baum-Welch算法(状态未知)——EM
 已知观测序列 O  ,估计模型λ = (pi, A , B)的参数,使得在该模型下观测序列P(O|λ)最大
 3. 预测问题:Viterbi算法——动态规划
 解码问题:已知模型λ = (pi, A , B)和观测序列 O
 求给定观测序列条件概率P(I|O, λ )最大的状态序列I
 --------------------------------------------------------
perceptron.py

感知机学习算法的原始形式

具体推导过程见李航《统计学习方法》第2章感知机  2.3.1 感知机学习算法的原始形式

tips:
  1. 感知机(perceptron)是二类分类的线性分类模型,其输入为实例的特征向量,输出
  为实例的类别,取+1和–1二值。
  2. 当训练数据集是线性可分的，感知机算法的原始形式是收敛的。
  --------------------------------------------------------
perceptron_duality.py

感知机学习算法的对偶形式

具体推导过程见李航《统计学习方法》第2章感知机  2.3.3 感知机学习算法的对偶形式
对偶形式中训练实例仅以内积的形式出现。为了方便,可以预先将训练集中实例间的
内积计算出来并以矩阵的形式存储,这个矩阵就是Gram矩阵。

------------------------------------------------------------
kNN.py 

k近邻算法

分类时,对新的实例,根据其k个最近邻的训练实例的类别,
通过多数表决等方式进行预测。
具体推导过程见李航《统计学习方法》第3章 k近邻法 3.2 k近邻模型

-------------------------------------------------------------
kd_tree.py

kd tree 最近邻搜索

具体推导过程见李航《统计学习方法》第3章 k近邻法   3.3 k近邻法的实现:kd树
kd树是二叉树,表示对k维空间的一个划分,其每个结
点对应于k维空间划分中的一个超矩形区域。利用kd树可以省去对大部分数据点的搜索,
从而减少搜索的计算量。

--------------------------------------------------------------
naive_bayes.py

朴素贝叶斯方法分类

参见李航 统计学习方法 第4章 朴素贝叶斯法

朴素贝叶斯(naïve Bayes)法是基于贝叶斯定理与特征条件独立假设的分类方法。
对于给定的训练数据集,首先基于特征条件独立假设学习输入/输出的联合概率分布;
然后基于此模型,对给定的输入x,利用贝叶斯定理求出后验概率最大的输出y。
